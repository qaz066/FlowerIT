# -*- coding: utf-8 -*-
"""EfficientNetB3_2c.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bObNoyXU9eYm5JRxibYSmb4Ucw8sL5GP
"""

from google.colab import drive
drive.mount('/content/drive')

# ==== 0) 제너레이터 준비 (이미 있다면 이 블록은 건너뛰어도 됨) ====
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG = (300, 300)   # EfficientNetB3 권장 해상도
BATCH = 32
train_datagen = ImageDataGenerator(rescale=1./255)  # 이미 /255 적용 중
val_datagen   = ImageDataGenerator(rescale=1./255)

train_dir = '/content/drive/MyDrive/TS/dataset/train'
val_dir   = '/content/drive/MyDrive/TS/dataset/val'

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=IMG, batch_size=BATCH,
    class_mode='categorical', shuffle=True)
val_generator = val_datagen.flow_from_directory(
    val_dir, target_size=IMG, batch_size=BATCH,
    class_mode='categorical', shuffle=False)

# ==== 1) class_weight 자동 계산 ====
import numpy as np
ci = train_generator.class_indices
labels = train_generator.classes
num_classes = len(ci)
counts = np.bincount(labels, minlength=num_classes)
N = counts.sum()
class_weight = {i: (N / (num_classes * counts[i])) for i in range(num_classes)}
cw = class_weight.copy()
cw[1] = cw[1] * 1.2   # 1.2~1.8 사이 탐색
print("클래스 순서:", sorted(ci, key=ci.get))
print("클래스별 개수:", counts.tolist())
print("class_weight:", cw)

# ==== 2) 모델: 증강 + EfficientNetB3 (/255 → 255 되돌린 뒤 투입) ====
import tensorflow as tf
from tensorflow.keras import layers, models

data_aug = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.08),
    layers.RandomTranslation(0.12, 0.12),
    layers.RandomZoom(0.0, 0.25),
    layers.RandomContrast(0.1),
    layers.RandomBrightness(0.1),
], name="aug")

# EfficientNetB3 본체
base = tf.keras.applications.EfficientNetB3(
    include_top=False, weights='imagenet', input_shape=IMG+(3,))
base.trainable = False  # Stage 1: 특징추출

inp = layers.Input(IMG+(3,))
x = data_aug(inp)

# 제너레이터에서 /255 했으므로, EfficientNet의 내부 전처리(Rescaling/Normalization)와 중복 방지:
# [0,1] → [0,255]로 되돌려서 base에 입력
x = layers.Rescaling(255.0, name="undo_div255")(x)

x = base(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
out = layers.Dense(num_classes, activation='softmax')(x)
model = models.Model(inp, out)

# ==== 3) Stage 1: 특징추출 ====
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=7e-4),
              loss='categorical_crossentropy', metrics=['accuracy'])

es  = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)
rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)

history1 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=8,
    class_weight=cw,
    callbacks=[es, rlr]
)

# ==== 4) Stage 2: 파인튜닝 (상위 블록만 해제, BN 고정) ====
for l in base.layers:
    # EfficientNetB3의 상위 스테이지(block6, block7)만 미세조정 권장
    if any(tag in l.name for tag in ['block6', 'block7']):
        if isinstance(l, layers.BatchNormalization):
            l.trainable = False
        else:
            l.trainable = True
    else:
        l.trainable = False

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),
              loss='categorical_crossentropy', metrics=['accuracy'])

history2 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,
    class_weight=cw,
    callbacks=[es, rlr]
)

# ==== 5) 최종 검증: test 세트 정확도 ====
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

TEST_DIR = '/content/drive/MyDrive/TS/dataset/test'  # test/healthy, test/sick
test_datagen = ImageDataGenerator(rescale=1./255)

# 훈련 때의 라벨 순서를 그대로 강제
class_names = sorted(ci, key=ci.get)  # 예: ['healthy', 'sick']

test_generator = test_datagen.flow_from_directory(
    TEST_DIR,
    target_size=IMG,
    batch_size=BATCH,
    class_mode='categorical',
    shuffle=False,               # 평가이므로 False
    classes=class_names          # ★ 훈련과 동일 인덱스 순서 강제
)

# 1) 전체 정확도/손실
test_loss, test_acc = model.evaluate(test_generator, verbose=0)
print("\n===== [TEST] 전체 =====")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Acc : {test_acc*100:.2f}%")

# 2) 클래스별 정확도
test_generator.reset()
probs = model.predict(test_generator, verbose=0)   # (N, num_classes)
y_pred = np.argmax(probs, axis=1)                  # 예측 라벨(정수)
y_true = test_generator.classes                    # 실제 라벨(정수)

idx_to_cls = {v:k for k,v in ci.items()}
print("\n라벨 매핑 확인:", ci)

for i, cls in enumerate(class_names):
    m = (y_true == i)
    cnt = int(m.sum())
    corr = int((y_pred[m] == i).sum())
    acc = (corr/cnt*100.0) if cnt>0 else 0.0
    print(f"\n[TEST] {cls}")
    print(f"- 이미지 개수: {cnt}")
    print(f"- 정확도     : {acc:.2f}%")

# 3) 혼동행렬 / 분류 리포트
cm = confusion_matrix(y_true, y_pred)
print("\n[Confusion Matrix]\n", cm)

print("\n[Classification Report]\n",
      classification_report(y_true, y_pred, target_names=class_names, digits=4))

# (선택) 예측 분포 참고
pred_counts = {class_names[i]: int((y_pred==i).sum()) for i in range(len(class_names))}
print("\n예측 분포:", pred_counts)

import os
SAVE_DIR  = "/content/drive/MyDrive/TS"
model.save('/content/drive/MyDrive/TS/EfficientNetB3.keras')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]   # 동적범위 양자화
tflite = converter.convert()
with open(os.path.join(SAVE_DIR, "EfficientNetB3.tflite"), "wb") as f:
    f.write(tflite)
print("Saved:", SAVE_DIR)

import json
with open("labels.json", "w", encoding="utf-8") as f:
    # 예: {'healthy': 0, 'sick': 1, ...}  ← train_generator.class_indices
    json.dump(ci, f, ensure_ascii=False, indent=2)

from google.colab import files
files.download("labels.json")

# # 0) 구글 드라이브 마운트
# from google.colab import drive
# drive.mount('/content/drive')

# # 1) 라이브러리
# import tensorflow as tf
# from tensorflow.keras.preprocessing.image import ImageDataGenerator
# from tensorflow.keras.applications import EfficientNetB3
# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
# from tensorflow.keras.models import Model
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
# from tensorflow.keras.preprocessing import image
# import numpy as np
# import glob, os

# # 2) 경로설정
# train_dir = '/content/drive/MyDrive/TS/datasets/flowers'
# val_dir   = '/content/drive/MyDrive/TS/datasets/val'
# SAVE_DIR  = "/content/drive/MyDrive/TS"

# # 3) 데이터증강
# train_datagen = ImageDataGenerator(
#     rescale=1./255,
#     rotation_range=45,
#     width_shift_range=0.3,
#     height_shift_range=0.3,
#     shear_range=0.3,
#     zoom_range=0.4,
#     horizontal_flip=True,
#     vertical_flip=True,
#     brightness_range=[0.6, 1.4],
#     channel_shift_range=40.0,
#     fill_mode='reflect',
# )

# val_datagen = ImageDataGenerator(rescale=1./255)

# # ✅ 4) 데이터 생성기 (EfficientNetB3 권장 입력: 300x300)
# IMG_SIZE = (300, 300)
# BATCH    = 32

# train_generator = train_datagen.flow_from_directory(
#     train_dir,
#     target_size=IMG_SIZE,
#     batch_size=BATCH,
#     class_mode='categorical'
# )

# val_generator = val_datagen.flow_from_directory(
#     val_dir,
#     target_size=IMG_SIZE,
#     batch_size=BATCH,
#     class_mode='categorical'
# )

# # 5) EfficientNetB3 + 전이학습
# base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
# for layer in base_model.layers:
#     layer.trainable = False  # Step1: feature extractor

# x = base_model.output
# x = GlobalAveragePooling2D()(x)
# x = Dropout(0.3)(x)  # 과적합 방지
# x = Dense(512, activation='relu')(x)
# x = Dropout(0.3)(x)
# output = Dense(train_generator.num_classes, activation='softmax')(x)
# model = Model(inputs=base_model.input, outputs=output)

# # 6) 콜백
# checkpoint = ModelCheckpoint('best_efficientnetB3.keras', save_best_only=True, monitor='val_loss', mode='min', verbose=1)
# early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
# reduce_lr  = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)
# callbacks  = [checkpoint, early_stop, reduce_lr]

# # 7) 모델 컴파일 및 1단계 학습 (헤드만 학습)
# #   - 전이학습 1단계는 보통 1e-3 ~ 1e-4가 안정적입니다.
# model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])
# model.summary()

# history = model.fit(
#     train_generator,
#     steps_per_epoch=train_generator.samples // train_generator.batch_size,
#     epochs=10,
#     validation_data=val_generator,
#     validation_steps=val_generator.samples // val_generator.batch_size,
#     callbacks=callbacks
# )

# # 8) fine-tuning 단계: 상위 일부 레이어 unfreeze 후 미세 조정
# #    - EfficientNet은 깊어서 너무 많이 풀면 불안정할 수 있어 마지막 블록 위주로 푸는 걸 권장
# for layer in base_model.layers[-30:]:
#     layer.trainable = True

# # 파인튜닝은 학습률을 크게 낮추는 게 핵심
# model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])

# history_finetune = model.fit(
#     train_generator,
#     steps_per_epoch=train_generator.samples // train_generator.batch_size,
#     epochs=5,  # 필요시 늘려도 됩니다 (early stop이 막아줌)
#     validation_data=val_generator,
#     validation_steps=val_generator.samples // val_generator.batch_size,
#     callbacks=callbacks
# )

# # 9) 단일 클래스(rose)로 간단 평가
# test_rose_dir = '/content/drive/MyDrive/testset/rose'  # rose 이미지만 있는 폴더
# img_paths = glob.glob(os.path.join(test_rose_dir, '*.jpg'))

# class_labels = list(train_generator.class_indices.keys())
# assert 'rose' in class_labels, f"'rose' 클래스가 데이터셋에 없습니다. 현재: {class_labels}"
# rose_index = class_labels.index('rose')

# correct = 0
# total = len(img_paths)
# for path in img_paths:
#     img = image.load_img(path, target_size=IMG_SIZE)
#     img_array = image.img_to_array(img) / 255.0
#     img_array = np.expand_dims(img_array, axis=0)
#     pred = model.predict(img_array, verbose=0)
#     pred_label = np.argmax(pred[0])
#     if pred_label == rose_index:
#         correct += 1

# accuracy = correct / total * 100 if total > 0 else 0
# print(f"\n테스트(rose) 이미지 개수: {total}")
# print(f"모델이 rose로 예측한 이미지 개수: {correct}")
# print(f"정확도 (rose만 평가): {accuracy:.2f}%")

# # 10) 모델 저장
# save_path = os.path.join(SAVE_DIR, 'flower_model_EfficientNetB3.keras')
# model.save(save_path)
# print(f"✅ 모델 저장 완료: {save_path}")